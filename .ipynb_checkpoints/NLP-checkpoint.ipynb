{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on the dialog box click on All Packages\n",
    "gutenberg\n",
    "sentiwordnet\n",
    "stopwords\n",
    "wordnet\n",
    "\"download\" these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.corpus.gutenberg.raw('carrol-alice.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.sent_tokenize(\"this is a sentence. So is this\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.sent_tokenize(nltk.corpus.gutenberg.raw('carrol-alice.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.word_tokenize(\"This is a sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[nltk.work_tokenize(s) for s in nltk.sent_tokenize(nltk.corpus.gutenberg.raw('carrol-alice.txt'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_text = \"This is a sentence. These sentences are repititive. But they are different\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.sent_tokenize(sample_text):\n",
    "words = nltk.word_tokenize(sent)\n",
    "print words"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "word_counts = []\n",
    "words_used = set()\n",
    "for sent in nltk.sent_tokenize(sample_text):\n",
    "    words = [x for x in nltk.word_tokenize(sent) if x != '.]'\n",
    "    word_counts.append(len(words))\n",
    "    for w in words:\n",
    "        words_used.add(w.upper())\n",
    "    print words\n",
    "print \"word counts per sentence\", word_counts\n",
    "print \"word count overall\", sum(word_counts)\n",
    "print \"Distinct words\", len(words_used)\n",
    "print \"Lexical diversity=\" 1.0*len(words_used)/sum(word_counts)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "words = nltk.word_tokenize(nltk.corpus.gutenberg.raw('carrol-alice.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alice = nltk.Text(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alice.concordance('rabbit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alice.similar(''rabbit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hamlet_words = nltk.word_tokenize(nltk.corpus.gutenberg.raw('shakespear-hamlet.txt')\n",
    "hamlet = nltk.Text(hamlet_words)\n",
    "hamlet.similar('Hamlet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alice.common_context(['rabbit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alice.dispersion.plot(['Rabbit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alice.dispersion.plot(['Rabbit', 'Hatter'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk.stem.porter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk.stem.snowball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.stem.snowball.SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snowball.stem(\"running\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "porter = nltk.stem.porter.PorterStemmer()\n",
    "porter.stem(\"running\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_counts = []\n",
    "words_used = set()\n",
    "word_stems = set()\n",
    "for sent in nltk.sent_tokenize(nltk.corpus.gutenberg.raw('carrol-alice.txt')):\n",
    "    words = [x for x in nltk.word_tokenize(sent) if x not in [ '.', '?']\n",
    "    word_counts.append(len(words))\n",
    "    for w in words:\n",
    "        word_stems.add(snowball.stem(w.lower()))\n",
    "        words_used.add(w.upper())\n",
    "    print words\n",
    "print \"word counts per sentence\", word_counts\n",
    "print \"word count overall\", sum(word_counts)\n",
    "print \"Distinct words\", len(words_used)\n",
    "print \"Lexical diversity=\" 1.0*len(words_used)/sum(word_counts)\n",
    "print \"Lexical stem diversity = \", 1.0 * len(word_stems) / sum(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.corpus.wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.corpus.wordnet.synsets(\"car\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.corpus.wordnet.synsets(\"hippopotamus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.corpus.wordnet.synsets(\"car\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.corpus.wordnet.synsets(\"car\")[0].definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.corpus.wordnet.synsets(\"car\")[1].definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.corpus.wordnet.synsets(\"car\")[2].definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.corpus.wordnet.synsets(\"car\")[3].definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.corpus.wordnet.synsets(\"car\")[0].lemma_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.corpus.wordnet.synsets(\"car\")[1].lemma_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.corpus.wordnet.synsets(\"railcar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.corpus.wordnet.synsets(\"car\")[0].hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.corpus.wordnet.synsets(\"car\")[0].hypernyms()[0].hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.corpus.wordnet.synsets(\"car\")[0].hypernyms()[0].hypernyms()[0].hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "motor_vehicle = nltk.corpus.wordnet.synsets(\"car\")[0].hypernyms()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "motor_vehicle.hyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "motor_car = nltk.corpus.wordnet.synsets(\"car\")[0]\n",
    "bicycle = nltk.corpus.wordnet.synsets(\"bicycle\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "motor_car.common_hypernyms(bicycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "motor_car.lowest_common_hypernyms(bicycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "motor_car.path_similarity(bicycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "carrot = nltk.corpus.wordnet.synsets(\"carrot\")\n",
    "#[s.definistion() for s in carrot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "motor_car.path_similarity(carrot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.pos_tag(nltk.word_tokenizer(\"I brought a frog.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = nltk.sent_tokenze(nltk.corpus.gutenberg.raw('carrol-alice.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.pos_tag(nltk.word_tokenize(s))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for s in nltk.sent_tokenze(nltk.corpus.gutenberg.raw('carrol-alice.txt')):\n",
    "words = nltk.word_tokenize(s)\n",
    "tagged  = nltk.po_tag(words)\n",
    "    for (word, part_of_speech) in tagged\n",
    "        if part_of_speech == 'VBD' and word == 'was':\n",
    "            was = True\n",
    "            countinue\n",
    "        if was and part_of_speech"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
